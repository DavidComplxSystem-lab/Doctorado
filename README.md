# J-optimizado: Implementaciones r√°pidas de la medida J

**J-optimizado** es un proyecto de benchmarking y optimizaci√≥n de la **medida J**, un √≠ndice basado exclusivamente en las **fases de Fourier** que permite detectar **determinismo**, **irregularidad**, **no linealidad** y estructuras din√°micas en series de tiempo sin necesidad de reconstrucci√≥n del espacio de fases.

La medida J se calcula a partir de la **caminata de fases** en el **toro 2D** (fase del primer canal vs fase del segundo canal) y de la **diferencia de √°ngulo** entre pasos consecutivos.

Este repositorio incluye diferentes versiones del mismo algoritmo, desde la implementaci√≥n original basada en ciclos hasta versiones totalmente vectorizadas, aceleradas con GPU y optimizadas para batch processing.

---

## üìò Art√≠culo original de la medida J

La implementaci√≥n sigue la metodolog√≠a descrita en:

> Aguilar-Hern√°ndez AI, Serrano-Sol√≠s DM, R√≠os-Herrera WA, Zapata-Berruecos JF, Vilaclara G, Mart√≠nez-Mekler G, M√ºller MF.  
> **Fourier phase index for extracting signatures of determinism and nonlinear features in time series**.  
> *Chaos*. 2024;34(1):013103. DOI: 10.1063/5.0160555.

Este trabajo demuestra que la medida J:

- Detecta regularidad/determinismo en datos con ruido.  
- Es sensible a estructuras no lineales.  
- Funciona en se√±ales reales como EEG intracraneal.  
- No requiere t√©cnicas como espacio de fases o surrogados.

---

## üìÅ Contenido del repositorio

### `J_measure.py`
Contiene todas las versiones de la medida J:

| Versi√≥n | Tecnolog√≠as | Descripci√≥n |
|--------|--------------|-------------|
| `toro` | NumPy + ciclos | Implementaci√≥n original, clara pero lenta. |
| `toro2` | NumPy vectorizado | Reemplaza ciclos por matrices; usa b√∫squeda expl√≠cita de 9 cuadrantes. |
| `toro2_1` | NumPy | Usa envoltura modular en lugar de 9 cuadrantes; m√°s simple y r√°pida. |
| `toro2_2` | NumPy + complejos | M√°xima velocidad en CPU; usa n√∫meros complejos para reducir memoria y operaciones. |
| `toro2_2_torch_batch` | PyTorch (CPU/CUDA/MPS) | Versi√≥n por lotes; permite procesar cientos/miles de pares de se√±ales en paralelo en CPU, GPU NVIDIA o GPU Apple Silicon (M1/M2). |

---

## üöÄ ¬øQu√© mejoras trae cada versi√≥n?

### ‚úî `toro` ‚Äî Versi√≥n base  
- Implementaci√≥n directa.  
- Usa ciclos Python.  
- Sirve como referencia y validaci√≥n, pero es lenta.

### ‚úî `toro2` ‚Äî Vectorizaci√≥n NumPy  
- Elimina ciclos.  
- Representa los 9 posibles desplazamientos del toro usando un arreglo 3D.  
- Mucho m√°s r√°pida que `toro`.

### ‚úî `toro2_1` ‚Äî Envoltura modular  
- Observa que los 9 cuadrantes equivalen a envolver `p2 - 2*p1`.  
- Simplifica el c√≥digo y reduce memoria.  
- Rendimiento mayor.

### ‚úî `toro2_2` ‚Äî Optimizaci√≥n con complejos  
- Representa cada vector como `x + i y`.  
- Usa la multiplicaci√≥n compleja para obtener producto punto y cruz.  
- M√≠nima memoria y m√°xima velocidad en CPU.  
- Versi√≥n recomendada si usas s√≥lo NumPy.

### ‚úî `toro2_2_torch_batch` ‚Äî PyTorch (CPU + GPU + MPS)  
- Procesa **m** pares de se√±ales simult√°neamente.  
- Compatible con:
  - CPU
  - GPU NVIDIA (`cuda`)
  - GPU Apple Silicon (`mps`)  
- √ötil para grandes lotes o integraci√≥n con frameworks de aprendizaje autom√°tico.

---

## üß™ `J-paralelizada.ipynb`

Este notebook incluye:

- Comparaci√≥n de tiempos entre todas las versiones.
- Paralelizaci√≥n CPU con `joblib`.
- Aceleraci√≥n multicapa con PyTorch (CPU/CUDA/MPS).
- Gr√°ficas y tablas de rendimiento.

---

## üîß Instalaci√≥n

### Dependencias principales

```bash
pip install torch torchvision torchaudio
