# üß© J-optimizado y D-optimizado
Implementaciones r√°pidas de medidas basadas en fases de Fourier para detectar determinismo y no linealidad en series de tiempo

**J-optimizado** es un proyecto de benchmarking y optimizaci√≥n de la **medida J**, un √≠ndice basado exclusivamente en las **fases de Fourier** que permite detectar **determinismo**, **irregularidad**, **no linealidad** y estructuras din√°micas en series de tiempo sin necesidad de reconstrucci√≥n del espacio de fases.

La medida J se calcula a partir de la **caminata de fases** en el **toro 2D** (fase del primer canal vs fase del segundo canal) y de la **diferencia de √°ngulo** entre pasos consecutivos.

Este repositorio tambi√©n incluye la **medida D**, una alternativa m√°s simple y eficiente basada en fases, actualmente **en revisi√≥n por la revista *Brain***.

---

## üìò Art√≠culo original de la medida J

La implementaci√≥n sigue la metodolog√≠a descrita en:

> Aguilar-Hern√°ndez AI, Serrano-Sol√≠s DM, R√≠os-Herrera WA, Zapata-Berruecos JF, Vilaclara G, Mart√≠nez-Mekler G, M√ºller MF.  
> **Fourier phase index for extracting signatures of determinism and nonlinear features in time series**.  
> *Chaos*. 2024;34(1):013103. DOI: 10.1063/5.0160555.

Este trabajo demuestra que J:

- Detecta regularidad/determinismo incluso con ruido.  
- Es sensible a estructuras no lineales.  
- Funciona en se√±ales reales como EEG intracraneal.  
- No requiere espacio de fases o surrogados.

---

## üìÅ Contenido del repositorio

### `J_measure.py`
Incluye todas las versiones optimizadas de la medida J:

| Versi√≥n | Tecnolog√≠as | Descripci√≥n |
|--------|-------------|-------------|
| `toro` | NumPy + ciclos | Implementaci√≥n original y m√°s lenta. |
| `toro2` | NumPy vectorizado | Sustituye los ciclos por matrices. |
| `toro2_1` | NumPy | Usa envoltura modular; m√°s simple y r√°pida. |
| `toro2_2` | NumPy + complejos | Versi√≥n m√°s eficiente en CPU. |
| `toro2_2_joblib_batch` | joblib | Computo paralelo por columnas (CPU). |
| `toro2_2_torch_batch` | PyTorch | Procesamiento por lotes en CPU, CUDA o MPS. |

---

### `D_measure.py`
Implementaci√≥n optimizada de la medida J (art√≠culo en revisi√≥n *Brain*):

| Versi√≥n | Tecnolog√≠as | Descripci√≥n |
|--------|-------------|-------------|
| `toroD` | NumPy | Versi√≥n base, extremadamente ligera. |
| `toroD_joblib_batch` | joblib | Paralelizaci√≥n CPU. |
| `toroD_torch_batch` | PyTorch | Aceleraci√≥n masiva por lotes en CPU/CUDA/MPS. |

---

### `benchmark_J_D.ipynb`

Notebook que incluye:

- Comparaci√≥n de rendimiento entre todas las versiones  
- Paralelizaci√≥n con joblib  
- Aceleraci√≥n con PyTorch en CPU, GPU NVIDIA o GPU Apple Silicon  
- Resultados reproducibles con 100 √ó 100 pruebas  

---

## üöÄ Rendimiento aproximado

Benchmarks t√≠picos usando se√±ales de tama√±o `1000 √ó 100`, repetidos 100 veces:
-1toro2 ~50√ó m√°s r√°pido que toro
-toro2_1 ~82√ó m√°s r√°pido que toro
-toro2_2 ~100√ó m√°s r√°pido que toro
-toro2_2_joblib_batch ~38√ó m√°s r√°pido que toro
-toro2_2_torch_batch ~440√ó m√°s r√°pido que toro
-toroD ~74√ó m√°s r√°pido que toro
-toroD_joblib_batch ~40√ó m√°s r√°pido
-toroD_torch_batch ~675√ó m√°s r√°pido


### Hardware utilizado

- **GPU NVIDIA RTX 5070 Ti (CUDA)**  
  ‚Üí M√°ximo rendimiento observado (hasta 675√ó).

- **MacBook Pro M1 Pro (GPU 16-core, backend MPS)**  
  ‚Üí Rendimiento similar (3‚Äì10% menor que CUDA).

- **CPU multin√∫cleo**  
  ‚Üí Aceleraciones moderadas (~20‚Äì40√ó).

PyTorch **selecciona autom√°ticamente** el mejor backend disponible:
- `cuda` ‚Üí GPU NVIDIA  
- `mps` ‚Üí Apple Silicon (M1/M2)  
- `cpu` ‚Üí cualquier PC sin GPU compatible  

---

## üõ† Instalaci√≥n

### Dependencias generales
```bash
pip install numpy joblib
```

**PyTorch**
**GPU NVIDIA (CUDA)**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**Mac M1/M2 (Metal/MPS)**
```bash
pip install torch torchvision torchaudio
```

‚úâÔ∏è Contacto

David Michel Serrano Sol√≠s
davidser88@hotmail.com
