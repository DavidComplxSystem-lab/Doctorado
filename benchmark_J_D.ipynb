{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55bf73cf-f5c1-4b4e-8323-4f6525d5659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark of different J-measure implementations (J_measure.py)\n",
    "# Compares: toro (baseline), toro2, toro2_1, toro2_2, toro2_2 + joblib (parallel CPU)\n",
    "# and toro2_2_torch_batch (PyTorch: CPU/CUDA/MPS).\n",
    "\n",
    "import J_measure as jm\n",
    "import importlib\n",
    "importlib.reload(jm)          # Reloads the module in case it was modified\n",
    "import D_measure as dm\n",
    "import importlib\n",
    "importlib.reload(dm)\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Series size (n) and number of signal pairs (m)\n",
    "n = 1000\n",
    "m = 100\n",
    "\n",
    "# Test data: m pairs of random series of length n\n",
    "a = np.random.rand(n, m)\n",
    "b = np.random.rand(n, m)\n",
    "\n",
    "# Arrays to store timing results for 100 repetitions\n",
    "dt1 = np.zeros(100)  # toro\n",
    "dt2 = np.zeros(100)  # toro2\n",
    "dt3 = np.zeros(100)  # toro2_1\n",
    "dt4 = np.zeros(100)  # toro2_2\n",
    "dt5 = np.zeros(100)  # toro2_2 parallel (joblib)\n",
    "dt6 = np.zeros(100)  # toro2_2_torch_batch (PyTorch)\n",
    "dt7 = np.zeros(100)  # toroD\n",
    "dt8 = np.zeros(100)  # toroD_joblib_batch (joblib)\n",
    "dt9 = np.zeros(100)  # toroD_torch_batch (PyTorch)\n",
    "\n",
    "# Outer loop: repeat the experiment 100 times to average execution times\n",
    "for ii in range(100):\n",
    "    # --- toro (baseline implementation with loops) ---\n",
    "    tt1 = np.zeros(m)\n",
    "    start1 = timer()\n",
    "    for i in range(m):\n",
    "        tt1[i] = jm.toro(a[:, i], b[:, i], 2, int(n/2))\n",
    "    dt1[ii] = timer() - start1\n",
    "\n",
    "    # --- toro2 (Vectorized NumPy with explicit quadrants) ---\n",
    "    tt2 = np.zeros(m)\n",
    "    start2 = timer()\n",
    "    for i in range(m):\n",
    "        tt2[i] = jm.toro2(a[:, i], b[:, i], 2, int(n/2))\n",
    "    dt2[ii] = timer() - start2\n",
    "\n",
    "    # --- toro2_1 (Vectorized NumPy with modular wrapping) ---\n",
    "    tt3 = np.zeros(m)\n",
    "    start3 = timer()\n",
    "    for i in range(m):\n",
    "        tt3[i] = jm.toro2_1(a[:, i], b[:, i], 2, int(n/2))\n",
    "    dt3[ii] = timer() - start3\n",
    "\n",
    "    # --- toro2_2 (Optimized NumPy using complex numbers) ---\n",
    "    tt4 = np.zeros(m)\n",
    "    start4 = timer()\n",
    "    for i in range(m):\n",
    "        tt4[i] = jm.toro2_2(a[:, i], b[:, i], 2, int(n/2))\n",
    "    dt4[ii] = timer() - start4\n",
    "\n",
    "    # --- toro2_2 column-wise parallel (CPU, joblib.Parallel) ---\n",
    "    start5 = timer()\n",
    "    tt5 = jm.toro2_2_joblib_batch(a, b, 2, int(n/2))\n",
    "    dt5[ii] = timer() - start5\n",
    "\n",
    "    # --- toro2_2_torch_batch (PyTorch, batch on CPU/CUDA/MPS) ---\n",
    "    start6 = timer()\n",
    "    tt6 = jm.toro2_2_torch_batch(a, b, 2, n//2)  # returns a tensor of size m\n",
    "    dt6[ii] = timer() - start6\n",
    "\n",
    "    # --- toroD (Vectorized NumPy)\n",
    "    tt7 = np.zeros(m)\n",
    "    start7 = timer()\n",
    "    for i in range(m):\n",
    "        tt7[i] = dm.toroD(a[:, i], b[:, i], 2, int(n/2))\n",
    "    dt7[ii] = timer() - start7\n",
    "    \n",
    "    # --- toroD_joblib_batch column-wise parallel (CPU, joblib.Parallel) ---\n",
    "    start8 = timer()\n",
    "    tt8 = dm.toroD_joblib_batch(a, b, 2, int(n/2))\n",
    "    dt8[ii] = timer() - start8\n",
    "\n",
    "    # --- toroD_torch_batch (PyTorch, batch on CPU/CUDA/MPS) ---\n",
    "    start9 = timer()\n",
    "    tt9 = dm.toroD_torch_batch(a, b, 2, n//2)  # returns a tensor of size m\n",
    "    dt9[ii] = timer() - start9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f7ffe6-076e-4f62-9b98-d53fc1191e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to analyze 100 pairs of 1000 data points, averaged over 100 runs with toro: 1.303110475000003\n",
      "toro2 is on average (100 runs) 49.87 times faster than toro\n",
      "toro2_1 is on average (100 runs) 82.03 times faster than toro\n",
      "toro2_2 is on average (100 runs) 98.0 times faster than toro\n",
      "toro2_2_joblib_batch is on average (100 runs) 30.74 times faster than toro\n",
      "toro2_2_torch_batch is on average (100 runs) 46.42 times faster than toro\n",
      "toroD is on average (100 runs) 72.5 times faster than toro\n",
      "toroD_joblib_batch is on average (100 runs) 35.18 times faster than toro and 1.14 times faster than toro2_2_joblib_batch\n",
      "toroD_torch_batch is on average (100 runs) 630.2 times faster than toro and 13.57 times faster than toro2_2_torch_batch\n"
     ]
    }
   ],
   "source": [
    "# Relative performance summary compared to the baseline implementation (toro)\n",
    "print('Average time to analyze', m, 'pairs of', n, 'data points, averaged over 100 runs with toro:', np.mean(dt1))\n",
    "print('toro2 is on average (100 runs)', np.round(np.mean(dt1)/np.mean(dt2),2), 'times faster than toro')\n",
    "print('toro2_1 is on average (100 runs)', np.round(np.mean(dt1)/np.mean(dt3),2), 'times faster than toro')\n",
    "print('toro2_2 is on average (100 runs)', np.round(np.mean(dt1)/np.mean(dt4)), 'times faster than toro')\n",
    "print('toro2_2_joblib_batch is on average (100 runs)', np.round(np.mean(dt1)/np.mean(dt5),2), 'times faster than toro')\n",
    "print('toro2_2_torch_batch is on average (100 runs)', np.round(np.mean(dt1)/np.mean(dt6),2), 'times faster than toro')\n",
    "print('toroD is on average (100 runs)', np.round(np.mean(dt1)/np.mean(dt7),2), 'times faster than toro')\n",
    "print('toroD_joblib_batch is on average (100 runs)', np.round(np.mean(dt1)/np.mean(dt8),2), 'times faster than toro and', np.round(np.mean(dt5)/np.mean(dt8),2), 'times faster than toro2_2_joblib_batch')\n",
    "print('toroD_torch_batch is on average (100 runs)', np.round(np.mean(dt1)/np.mean(dt9),2), 'times faster than toro and', np.round(np.mean(dt6)/np.mean(dt9),2), 'times faster than toro2_2_torch_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f054252-d830-4dd6-a8d9-6445c3933b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
